
# Problem 1.8 

The Hoeffding Inequality is one form of the law of large numbers. One of the simplest forms of that law is the Chebyshev Inequality, which you will prove here.

(a) If $t$ is a non negative random variable, prove that for any $\alpha > 0$,  $P[t \geq \alpha] \leq \frac{E(t)}{\alpha}$

By definition, 

$P[t \geq \alpha] \triangleq \int_\alpha^\infty p(x) dx$

and

$E(t) \triangleq \int_{-\infty}^\infty x p(x) dx$

so evaluate

$\alpha \int_\alpha^\infty p(x) dx = \alpha P[t \geq \alpha] \leq E(t) = \int_{-\infty}^\infty x p(x) dx$

since $t$ is strictly positive, this can be written as

$\int_\alpha^\infty \alpha p(x) dx \geq \int_0^\alpha x p(x) dx + \int_\alpha^\infty x p(x) dx$

note that $\int_\alpha^\infty \alpha p(x) dx \geq \int_\alpha^\infty x p(x) dx$

and because $t > 0$, $\int_0^\alpha x p(x) dx \geq 0$

so it holds that $\alpha \int_\alpha^\infty p(x) dx = \int_{-\infty}^\infty x p(x) dx$

and thus $P[t \geq \alpha] \leq \frac{E(t)}{\alpha}$


(b) If u is any random variable with mean $\mu$ and variance $\sigma^2$, prove that for any $\alpha > 0, P[\left(u - \mu\right)^2 \geq \alpha ] \leq \frac{\sigma^2}{\alpha}$. [Hint: Use (a)]

By definition, 

$\sigma^2 \triangleq E[(u - \mu)^2]$

and thus with substitution of $t := \left(u - \mu\right)^2$ and using (a), we have

$P[\left(u - \mu\right)^2 \geq \alpha ] \leq \frac{\sigma^2}{\alpha}$


(c) If $u_1, \ldots , u_N$ are iid random variables, each with mean $\mu$ and variance $\sigma^2$, and $u = \frac{1}{N} \Sigma^N_{n=1} u_n$, prove that for any $\alpha > 0$, $P[(u - \mu)^2 \geq \alpha ] \leq \frac{\sigma^2}{N \alpha}$.

Notice that the RHS of this Chebyshev Inequality goes down linearly in N, while the counterpart in Hoeffding's Inequality goes down exponentially. In Problem 1.9, we develop an exponential bound using a similar approach.

